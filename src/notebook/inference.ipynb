{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "\n",
    "from dataset import (\n",
    "    InstanceSegmentationLazyDataset,\n",
    "    _files_in_dir,\n",
    ")\n",
    "from helper import (\n",
    "    boundaries_mirror_y,\n",
    "    masks_to_boundary,\n",
    "    model_masks_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(\"../../out/\")\n",
    "images_path = Path(\"../../data/test/\")\n",
    "boundaries_path = Path(\"../../data/test/\")\n",
    "output_dir = Path(\"../../data/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    torch.device(\"cuda\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_image_suffixes = [\".tif\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\n",
    "    checkpoint_path / \"model\" / \"best_model.tar\",\n",
    "    weights_only=False,\n",
    ")\n",
    "\n",
    "model: torch.nn.Module = checkpoint[\"model\"]\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "images = _files_in_dir(images_path)\n",
    "images = [i for i in images if i.suffix in _image_suffixes]\n",
    "\n",
    "for image_path in images:\n",
    "    image = Image.open(image_path)\n",
    "    image_tensor = TF.to_tensor(image).unsqueeze(0).to(device)\n",
    "\n",
    "    masks = model_masks_output(model, image_tensor)\n",
    "    boundaries = masks_to_boundary((masks * 255).astype(np.uint8))\n",
    "    boundaries_mirrored = boundaries_mirror_y(boundaries)\n",
    "    boundaries_mirrored.to_file(output_dir / f\"{image_path.stem}.shp\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "    boundaries.boundary.plot(ax=ax, edgecolor=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Segmentation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\n",
    "    checkpoint_path / \"model\" / \"best_model.tar\",\n",
    "    weights_only=False,\n",
    ")\n",
    "\n",
    "model: torch.nn.Module = checkpoint[\"model\"]\n",
    "# model.to(device)\n",
    "\n",
    "dataset = InstanceSegmentationLazyDataset(images_path, boundaries_path)\n",
    "\n",
    "for image_boundary_pair in dataset:\n",
    "    with torch.no_grad():\n",
    "        model.train()\n",
    "        loss = model([image_boundary_pair[0]], [image_boundary_pair[1]])\n",
    "\n",
    "    for k, v in loss.items():\n",
    "        print(f\"{k}: {v.item()}\")\n",
    "\n",
    "    real_mask = image_boundary_pair[1][\"masks\"]\n",
    "    real_boundaries = masks_to_boundary((real_mask * 255).numpy().astype(np.uint8))\n",
    "\n",
    "    model.eval()\n",
    "    model_mask = model_masks_output(model, [image_boundary_pair[0]])\n",
    "    model_boundaries = masks_to_boundary((model_mask * 255).astype(np.uint8))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(image_boundary_pair[0].permute(1, 2, 0))\n",
    "    real_boundaries.boundary.plot(ax=ax, edgecolor=\"red\", alpha=0.5)\n",
    "    model_boundaries.boundary.plot(ax=ax, edgecolor=\"blue\", alpha=0.5)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
